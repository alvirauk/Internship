{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\alvir\\anaconda3\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\alvir\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26daeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add59e2f",
   "metadata": {},
   "source": [
    "#Q1Scrape the details of most viewed videos on YouTube from Wikipedia. Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc42e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ee6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = []\n",
    "name = []\n",
    "uploader = []\n",
    "views = []\n",
    "upload_date = []\n",
    "\n",
    "rows = driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr\") #(only rows)\n",
    "\n",
    "for row in rows[0:30]:\n",
    "    rank.append(row.find_element(By.XPATH, \"./td[1]\").text.strip('.')) #(each cell in the colum)\n",
    "    name.append(row.find_element(By.XPATH, \"./td[2]\").text)\n",
    "    uploader.append(row.find_element(By.XPATH, \"./td[3]\").text)\n",
    "    views.append(row.find_element(By.XPATH, \"./td[4]\").text)\n",
    "    upload_date.append(row.find_element(By.XPATH, \"./td[5]\").text)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Rank': rank,\n",
    "    'Video': name,\n",
    "    'Uploader': uploader,\n",
    "    'Views': views,\n",
    "    'Upload Date': upload_date\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5ffc5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                       Video Name  \\\n",
      "0     1                            \"Baby Shark Dance\"[6]   \n",
      "1     2                                   \"Despacito\"[9]   \n",
      "2     3                       \"Johny Johny Yes Papa\"[17]   \n",
      "3     4                                  \"Bath Song\"[18]   \n",
      "4     5                               \"Shape of You\"[19]   \n",
      "5     6                              \"See You Again\"[22]   \n",
      "6     7                          \"Wheels on the Bus\"[27]   \n",
      "7     8                \"Phonics Song with Two Words\"[28]   \n",
      "8     9                                \"Uptown Funk\"[29]   \n",
      "9    10  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]   \n",
      "10   11                              \"Gangnam Style\"[31]   \n",
      "11   12   \"Masha and the Bear ‚Äì Recipe for Disaster\"[36]   \n",
      "12   13                             \"Dame Tu Cosita\"[37]   \n",
      "13   14                                     \"Axel F\"[38]   \n",
      "14   15                                      \"Sugar\"[39]   \n",
      "15   16                             \"Counting Stars\"[40]   \n",
      "16   17                                       \"Roar\"[41]   \n",
      "17   18                        \"Baa Baa Black Sheep\"[42]   \n",
      "18   19           \"Waka Waka (This Time for Africa)\"[43]   \n",
      "19   20                             \"Lakdi Ki Kathi\"[44]   \n",
      "20   21                                      \"Sorry\"[45]   \n",
      "21   22                          \"Thinking Out Loud\"[46]   \n",
      "22   23          \"Humpty the train on a fruits ride\"[47]   \n",
      "23   24                                 \"Dark Horse\"[48]   \n",
      "24   25                                    \"Perfect\"[49]   \n",
      "25   26                                 \"Let Her Go\"[50]   \n",
      "26   27                                      \"Faded\"[51]   \n",
      "27   28                      \"Shree Hanuman Chalisa\"[52]   \n",
      "28   29                             \"Girls Like You\"[53]   \n",
      "29   30                                    \"Lean On\"[54]   \n",
      "\n",
      "                                             Uploader Views (billions)  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories            13.65   \n",
      "1                                          Luis Fonsi             8.32   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs             6.84   \n",
      "3                          Cocomelon - Nursery Rhymes             6.50   \n",
      "4                                          Ed Sheeran             6.14   \n",
      "5                                         Wiz Khalifa             6.09   \n",
      "6                          Cocomelon - Nursery Rhymes             5.71   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs             5.57   \n",
      "8                                         Mark Ronson             5.09   \n",
      "9                                         Miroshka TV             5.01   \n",
      "10                                        officialpsy             4.96   \n",
      "11                                         Get Movies             4.57   \n",
      "12                                      Ultra Records             4.48   \n",
      "13                                         Crazy Frog             4.16   \n",
      "14                                           Maroon 5             3.97   \n",
      "15                                        OneRepublic             3.92   \n",
      "16                                         Katy Perry             3.91   \n",
      "17                         Cocomelon - Nursery Rhymes             3.84   \n",
      "18                                            Shakira             3.78   \n",
      "19                                       Jingle Toons             3.76   \n",
      "20                                      Justin Bieber             3.74   \n",
      "21                                         Ed Sheeran             3.69   \n",
      "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs             3.63   \n",
      "23                                         Katy Perry             3.63   \n",
      "24                                         Ed Sheeran             3.60   \n",
      "25                                          Passenger             3.56   \n",
      "26                                        Alan Walker             3.55   \n",
      "27                              T-Series Bhakti Sagar             3.54   \n",
      "28                                           Maroon 5             3.52   \n",
      "29                               Major Lazer Official             3.50   \n",
      "\n",
      "          Upload Date  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4    January 30, 2017  \n",
      "5       April 6, 2015  \n",
      "6        May 24, 2018  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9   February 27, 2018  \n",
      "10      July 15, 2012  \n",
      "11   January 31, 2012  \n",
      "12      April 5, 2018  \n",
      "13      June 16, 2009  \n",
      "14   January 14, 2015  \n",
      "15       May 31, 2013  \n",
      "16  September 5, 2013  \n",
      "17      June 25, 2018  \n",
      "18       June 4, 2010  \n",
      "19      June 14, 2018  \n",
      "20   October 22, 2015  \n",
      "21    October 7, 2014  \n",
      "22   January 26, 2018  \n",
      "23  February 20, 2014  \n",
      "24   November 9, 2017  \n",
      "25      July 25, 2012  \n",
      "26   December 3, 2015  \n",
      "27       May 10, 2011  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0986705",
   "metadata": {},
   "source": [
    "Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46f9b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4366a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "international_tab = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//button[normalize-space()='International']\"))\n",
    ")\n",
    "\n",
    "international_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb352738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "international_tab = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//button[normalize-space()='International']\"))\n",
    ")\n",
    "\n",
    "international_tab.click()\n",
    "\n",
    "OR\n",
    " EC.presence_of_all_elements_located((By.XPATH, \"//button\"))\n",
    ")\n",
    "\n",
    "# Iterate through buttons and click the one with the correct text, stripped of whitespace\n",
    "for button in buttons:\n",
    "    if button.text.strip() == 'International':\n",
    "        button.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dab431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUADRANGULAR MENS U19 ONE DAY SERIES']\n"
     ]
    }
   ],
   "source": [
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "series = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for s in series[0:1]:\n",
    "     Series.append(s.text)\n",
    "print(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97550276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DVR Ground,Mulapadu,']\n"
     ]
    }
   ],
   "source": [
    "info = driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in info[0:1]:\n",
    "    Place.append(i.text)\n",
    "print(Place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0882d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24 November, 2023']\n"
     ]
    }
   ],
   "source": [
    "date_all = driver.find_elements(By.XPATH,'//div[@class=\"match-info\"]/div')\n",
    "for d in date_all[0:1]:\n",
    "    Date.append(d.text.strip())\n",
    "print(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40e5a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3:30 AM GMT']\n"
     ]
    }
   ],
   "source": [
    "timings = driver.find_elements(By.XPATH,'//div[@class=\"match-info\"]/div[2]')\n",
    "for t in timings[0:1]:\n",
    "    Time.append(t.text)\n",
    "print(Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8805581",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf594a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b335bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b1e9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Economy')]\"))\n",
    ")\n",
    "economy_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64869fda",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m india \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m      2\u001b[0m     EC\u001b[38;5;241m.\u001b[39melement_to_be_clickable((By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m india_link\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:101\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "india = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]'))\n",
    ")\n",
    "india_link\n",
    "#For some reason no matter that i do it does not let me click on the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b865bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpi=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "gdpi.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5eb9bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp=[]\n",
    "gsdp1=[]\n",
    "share=[]\n",
    "gdp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "434a4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.XPATH, '//table[@class= \"display dataTable\"]/tbody/tr') \n",
    "\n",
    "for row in rows[0:33]:\n",
    "    rank.append(row.find_element(By.XPATH, \"./td[1]\").text.strip('.')) #(each cell in the colum)\n",
    "    state.append(row.find_element(By.XPATH, \"./td[2]\").text)\n",
    "    gsdp.append(row.find_element(By.XPATH, \"./td[3]\").text)\n",
    "    gsdp1.append(row.find_element(By.XPATH, \"./td[4]\").text)\n",
    "    share.append(row.find_element(By.XPATH, \"./td[5]\").text)\n",
    "    gdp.append(row.find_element(By.XPATH, \"./td[6]\").text)\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'Rank': rank,\n",
    "    'State': state,\n",
    "    'GSDP': gsdp,\n",
    "    'GSDP1': gsdp1,\n",
    "    'Share': share,\n",
    "    'GDP':gdp\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f43a4bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State       GSDP      GSDP1   Share      GDP\n",
      "0     1                Maharashtra          -  2,632,792  13.94%  399.921\n",
      "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%  247.629\n",
      "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%  240.726\n",
      "3     4                    Gujarat          -  1,502,899   7.96%  228.290\n",
      "4     5                  Karnataka  1,631,977  1,493,127   7.91%  226.806\n",
      "5     6                West Bengal  1,253,832  1,089,898   5.77%  165.556\n",
      "6     7                  Rajasthan  1,020,989    942,586   4.99%  143.179\n",
      "7     8             Andhra Pradesh    972,782    862,957   4.57%  131.083\n",
      "8     9                  Telangana    969,604    861,031   4.56%  130.791\n",
      "9    10             Madhya Pradesh    906,672    809,592   4.29%  122.977\n",
      "10   11                     Kerala          -    781,653   4.14%  118.733\n",
      "11   12                      Delhi    856,112    774,870   4.10%  117.703\n",
      "12   13                    Haryana    831,610    734,163   3.89%  111.519\n",
      "13   14                      Bihar    611,804    530,363   2.81%   80.562\n",
      "14   15                     Punjab    574,760    526,376   2.79%   79.957\n",
      "15   16                     Odisha    521,275    487,805   2.58%   74.098\n",
      "16   17                      Assam          -    315,881   1.67%   47.982\n",
      "17   18               Chhattisgarh    329,180    304,063   1.61%   46.187\n",
      "18   19                  Jharkhand    328,598    297,204   1.57%   45.145\n",
      "19   20                Uttarakhand          -    245,895   1.30%   37.351\n",
      "20   21            Jammu & Kashmir          -    155,956   0.83%   23.690\n",
      "21   22           Himachal Pradesh    165,472    153,845   0.81%   23.369\n",
      "22   23                        Goa     80,449     73,170   0.39%   11.115\n",
      "23   24                    Tripura     55,984     49,845   0.26%    7.571\n",
      "24   25                 Chandigarh          -     42,114   0.22%    6.397\n",
      "25   26                 Puducherry     38,253     34,433   0.18%    5.230\n",
      "26   27                  Meghalaya     36,572     33,481   0.18%    5.086\n",
      "27   28                     Sikkim     32,496     28,723   0.15%    4.363\n",
      "28   29                    Manipur     31,790     27,870   0.15%    4.233\n",
      "29   30                   Nagaland          -     27,283   0.14%    4.144\n",
      "30   31          Arunachal Pradesh          -     24,603   0.13%    3.737\n",
      "31   32                    Mizoram     26,503     22,287   0.12%    3.385\n",
      "32   33  Andaman & Nicobar Islands          -          -       -        -\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a39d31",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5f0a8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_nav_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID, \"dialog-show-dialog-ef659fb7-aa68-42e7-9306-e8caba7be47c\")))\n",
    "\n",
    "# Click on the button\n",
    "global_nav_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f0f9840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore=WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID,'item-b30f552c-3c7b-4e2b-bfeb-d934505d4ea2')))\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b87f55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]')))\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aade40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_use=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "375129f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bgstaal / multipleWindow3dScene', 'run-llama / rags', 'teslamotors / roadster', 'trungdq88 / Awesome-Black-Friday-Cyber-Monday', 'fanmingming / live', 'keiko233 / clash-nyanpasu', 'linexjlin / GPTs', 'wesbos / hot-tips', 'lllyasviel / Fooocus', 'florinpop17 / app-ideas', 'StarRocks / starrocks', 'antirez / botlib', 'GrowingGit / GitHub-Chinese-Top-Charts', '1Panel-dev / 1Panel', 'LouisShark / chatgpt_system_prompt', 'Stability-AI / generative-models', 'AmruthPillai / Reactive-Resume', 'microsoft / AI-For-Beginners', 'fffaraz / awesome-cpp', 'mRs- / Black-Friday-Deals', 'spring-projects / spring-boot', 'windmill-labs / windmill', 'sergiomarotco / Network-segmentation-cheat-sheet', 'CatVodTVOfficial / TVBoxOSC', 'angular / angular']\n"
     ]
    }
   ],
   "source": [
    "rep_title = driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in rep_title[0:25]:\n",
    "    Repository_title.append(i.text)\n",
    "print(Repository_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e520411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A quick example of how one can \"synchronize\" a 3d scene across multiple windows using three.js and localStorage', 'A quick example of how one can \"synchronize\" a 3d scene across multiple windows using three.js and localStorage', 'Build ChatGPT over your data, all with natural language', '2008-2012 Roadster Development and Diagnostic Software files', 'Awesome deals on Black Friday: Apps, SaaS, Books, Courses, etc.', '‚úØ ‰∏Ä‰∏™ÂèØÁõ¥ËøûËÆøÈóÆÁöÑÁîµËßÜ/ÂπøÊí≠ÂõæÊ†áÂ∫ì‰∏éÁõ∏ÂÖ≥Â∑•ÂÖ∑È°πÁõÆ ‚úØ üîï Ê∞∏‰πÖÂÖçË¥π Áõ¥ËøûËÆøÈóÆ ÂÆåÊï¥ÂºÄÊ∫ê ‰∏çÊñ≠ÂÆåÂñÑÁöÑÂè∞Ê†á ÊîØÊåÅIPv4/IPv6ÂèåÊ†àËÆøÈóÆ üîï', 'Clash Nyanpasu!', 'leaked prompts of GPTs', 'The code behind my hot tips', 'Focus on prompting and generating', 'A Collection of application ideas which can be used to improve your coding skills.', 'StarRocks, a Linux Foundation project, is a next-generation sub-second MPP OLAP database for full analytics scenarios, including multi-dimensional analytics, real-time analytics, and ad-hoc queries. InfoWorld‚Äôs 2023 BOSSIE Award for best open source software.', 'C Telegram bot framework', 'üá®üá≥ GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂêÑËØ≠Ë®ÄÂàÜËÆæ„ÄåËΩØ‰ª∂ | ËµÑÊñô„ÄçÊ¶úÂçïÔºåÁ≤æÂáÜÂÆö‰Ωç‰∏≠ÊñáÂ•ΩÈ°πÁõÆ„ÄÇÂêÑÂèñÊâÄÈúÄÔºåÈ´òÊïàÂ≠¶‰π†„ÄÇ', 'üî• üî• üî• Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø„ÄÇ', \"store all agent's system prompt\", 'Generative Models by Stability AI', 'A one-of-a-kind resume builder that keeps your privacy in mind. Completely secure, customizable, portable, open-source and free forever. Try it out today!', '12 Weeks, 24 Lessons, AI for All!', 'A curated list of awesome C++ (or C) frameworks, libraries, resources, and shiny things. Inspired by awesome-... stuff.', 'Black Friday Deals for macOS / iOS Software & Books', 'Spring Boot', 'Open-source developer platform to turn scripts into workflows and UIs. Open-source alternative to Airplane and Retool.', 'Best practices for segmentation of the corporate network of any company', 'ÁúüÁöÑÊ≤°ÊúâQQÁæ§„ÄÅQQÈ¢ëÈÅì„ÄÅËÆ∫Âùõ„ÄÇÊâìÂåÖÂàÜÂèëÊ≥®ÊÑèÂºÄÊ∫êÂçèËÆÆÔºå‰øùÁïôÂá∫Â§ÑÔºå‰∏çÂÆàËßÑÁü©Â∞±‰∏çË¶ÅÊêû„ÄÇ', 'Deliver web apps with confidence üöÄ']\n"
     ]
    }
   ],
   "source": [
    "rep_des = driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for e in rep_des[0:25]:\n",
    "    Repository_description.append(e.text)\n",
    "print(Repository_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a584271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JavaScript', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'Python', 'Java', 'C', 'Java', 'Go', 'Shell', 'Python', 'TypeScript', 'Jupyter Notebook', 'Swift', 'Java', 'JavaScript', 'Java', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "Lang_use = driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for l in Lang_use[0:25]:\n",
    "    Language_use.append(l.text)\n",
    "print(Language_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in info[0:1]:\n",
    "    Place.append(i.text)\n",
    "print(Place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a76985ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls = []\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start, end):\n",
    "        url=driver.find_elements(By.XPATH,'//a[@class = \"Link\"]')\n",
    "        for i in url:\n",
    "            product_urls.append(i.get_attribute(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e42cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/bgstaal/multipleWindow3dScene', 'https://github.com/run-llama/rags', 'https://github.com/teslamotors/roadster', 'https://github.com/trungdq88/Awesome-Black-Friday-Cyber-Monday', 'https://github.com/fanmingming/live', 'https://github.com/keiko233/clash-nyanpasu', 'https://github.com/linexjlin/GPTs', 'https://github.com/wesbos/hot-tips', 'https://github.com/lllyasviel/Fooocus', 'https://github.com/florinpop17/app-ideas', 'https://github.com/StarRocks/starrocks', 'https://github.com/antirez/botlib', 'https://github.com/GrowingGit/GitHub-Chinese-Top-Charts', 'https://github.com/1Panel-dev/1Panel', 'https://github.com/LouisShark/chatgpt_system_prompt', 'https://github.com/Stability-AI/generative-models', 'https://github.com/AmruthPillai/Reactive-Resume', 'https://github.com/microsoft/AI-For-Beginners', 'https://github.com/fffaraz/awesome-cpp', 'https://github.com/mRs-/Black-Friday-Deals', 'https://github.com/spring-projects/spring-boot', 'https://github.com/windmill-labs/windmill', 'https://github.com/sergiomarotco/Network-segmentation-cheat-sheet', 'https://github.com/CatVodTVOfficial/TVBoxOSC', 'https://github.com/angular/angular']\n"
     ]
    }
   ],
   "source": [
    "print(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bcb0353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(product_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d295ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "Contributors_count = []\n",
    "\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  \n",
    "    try:\n",
    "        conts_count_element = driver.find_element(By.XPATH, \"//span[contains(@class, 'Counter ml-1')]\")\n",
    "        Contributors_count.append(conts_count_element.text)  \n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append('-') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "289d7dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '-', '', '3', '', '', '', '10', '', '', '', '', '38', '', '', '1', '', '', '', '', '4', '', '', '1,814']\n"
     ]
    }
   ],
   "source": [
    "print(Contributors_count)   #it is getting for some but not for all of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a52d9596",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c3a164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39ecafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH, \"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "designation.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "972eb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_b=driver.find_element(By.XPATH, \"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button/span\")\n",
    "charts_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f665b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100=driver.find_element(By.XPATH, \"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a\")\n",
    "hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e79349",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17db81f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "name = driver.find_elements(By.XPATH,'//h3[@id=\"title-of-a-story\"]')\n",
    "for n in name[0:100]:\n",
    "    Song_name.append(n.text)\n",
    "print(len(Song_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1fdd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_n= driver.find_elements(By.XPATH,'//span[contains(@class,\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")]')\n",
    "for n in artist_n[0:100]:\n",
    "    Artist_name.append(n.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7039ac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Artist_name))  #fix this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fb61b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw=[]\n",
    "pos=[]\n",
    "woc=[]\n",
    "\n",
    "Details=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,\"//span[@class='a-font-primary-bold-l']\")]\n",
    "\n",
    "for i in Details:\n",
    "    lw.append(i[0])\n",
    "    pos.append(i[1])\n",
    "    woc.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "785ceca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=55834): Max retries exceeded with url: /session/dc1210b3dc33ef5c8150eec4522a61ec/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000168CFE01E50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28msuper\u001b[39m(HTTPConnection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000168CFE01E50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[1;32m----> 5\u001b[0m elements \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//span[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma-font-primary-bold-l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m lw \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m      7\u001b[0m pos \u001b[38;5;241m=\u001b[39m [] \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:770\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    766\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    342\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:300\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    298\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[0;32m    299\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:321\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    318\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 321\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m    322\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[0;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[0;32m    582\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[0;32m    583\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=55834): Max retries exceeded with url: /session/dc1210b3dc33ef5c8150eec4522a61ec/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000168CFE01E50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "elements = driver.find_elements(By.XPATH, \"//span[@class='a-font-primary-bold-l']\")\n",
    "lw = [] \n",
    "pos = [] \n",
    "woc = [] \n",
    "\n",
    "pattern = re.compile(r'\\d+')\n",
    "\n",
    "for element in elements:\n",
    "    data = element.text.split('\\n')\n",
    "    numeric_data = list(filter(pattern.match, data))\n",
    "    \n",
    "    if len(numeric_data) >= 3:  \n",
    "        lw.append(numeric_data[0])  \n",
    "        pos.append(numeric_data[1])  \n",
    "        woc.append(numeric_data[2])  \n",
    "    else:\n",
    "        lw.append('N/A')\n",
    "        pos.append('N/A')\n",
    "        woc.append('N/A')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print the extracted data\n",
    "print('Last Week:', lw)\n",
    "print('Position:', pos)\n",
    "print('Weeks on Chart:', woc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210b7ea",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "756bc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a85b5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book Name            Author  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes Sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//table[@class='in-article sortable']\"))\n",
    ")\n",
    "\n",
    "book_names = []\n",
    "authors = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "rows = driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr\")\n",
    "\n",
    "for row in rows:\n",
    "    book_name = row.find_element(By.XPATH, \".//td[2]\").text\n",
    "    author = row.find_element(By.XPATH, \".//td[3]\").text\n",
    "    volume_sold = row.find_element(By.XPATH, \".//td[4]\").text\n",
    "    publisher = row.find_element(By.XPATH, \".//td[5]\").text\n",
    "    genre = row.find_element(By.XPATH, \".//td[6]\").text\n",
    "\n",
    "    book_names.append(book_name)\n",
    "    authors.append(author)\n",
    "    volumes_sold.append(volume_sold)\n",
    "    publishers.append(publisher)\n",
    "    genres.append(genre)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Book Name': book_names,\n",
    "    'Author': authors,\n",
    "    'Volumes Sold': volumes_sold,\n",
    "    'Publisher': publishers,\n",
    "    'Genre': genres\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69d42a",
   "metadata": {},
   "source": [
    "Q7.Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dd178761",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ae3ec2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c8ffddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "name = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for n in name[0:100]:\n",
    "    Name.append(n.text)\n",
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b925eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters: The Mortal Instruments', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House M.D.', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', 'Legends of Tomorrow', \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House']\n"
     ]
    }
   ],
   "source": [
    "print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a8359dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "year = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for y in year[0:100]:\n",
    "    Year_span.append(y.text)\n",
    "print(len(Year_span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "568830ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(2011‚Äì2019)', '(2016‚Äì2025)', '(2010‚Äì2022)', '(2017‚Äì2020)', '(2014‚Äì2020)', '(2013‚Äì2019)', '(2017‚Äì2023)', '(2005‚Äì )', '(2014‚Äì2023)', '(2012‚Äì2020)', '(2017‚Äì2021)', '(2007‚Äì2019)', '(2011‚Äì )', '(2010‚Äì2017)', '(2013‚Äì2020)', '(2010‚Äì2017)', '(2009‚Äì2017)', '(2011‚Äì )', '(2008‚Äì2013)', '(2016‚Äì2021)', '(2005‚Äì2020)', '(2005‚Äì2017)', '(2014‚Äì2020)', '(2011‚Äì2017)', '(1989‚Äì )', '(2011‚Äì2018)', '(I) (2015‚Äì2017)', '(2015‚Äì2018)', '(1994‚Äì2004)', '(2005‚Äì2014)', '(2011‚Äì2019)', '(2015‚Äì2019)', '(2013‚Äì2018)', '(2015‚Äì2021)', '(2007‚Äì2012)', '(2015‚Äì2018)', '(2014‚Äì2019)', '(2016‚Äì2022)', '(2015‚Äì2019)', '(2009‚Äì2020)', '(2013‚Äì )', '(2016‚Äì2019)', '(2017‚Äì2019)', '(2013‚Äì2018)', '(2017‚Äì2020)', '(2018‚Äì2024)', '(2019‚Äì2023)', '(2011‚Äì2021)', '(2011‚Äì2018)', '(2013‚Äì2020)', '(2018‚Äì2024)', '(2006‚Äì2013)', '(2015‚Äì2023)', '(1999‚Äì )', '(2013‚Äì2023)', '(2004‚Äì2010)', '(2013‚Äì2022)', '(2004‚Äì2012)', '(2015‚Äì2018)', '(2013‚Äì2017)', '(2011‚Äì2020)', '(2015‚Äì2020)', '(2016‚Äì2022)', '(2017‚Äì )', '(2018‚Äì2020)', '(2017‚Äì )', '(2014‚Äì2019)', '(2009‚Äì2015)', '(1997‚Äì )', '(2013‚Äì2021)', '(2013‚Äì2015)', '(2019‚Äì2024)', '(2014‚Äì )', '(2016‚Äì2019)', '(2004‚Äì2012)', '(2015‚Äì2022)', '(2013‚Äì2017)', '(2017‚Äì2019)', '(2017‚Äì2021)', '(2017‚Äì2022)', '(2016‚Äì2022)', '(2016‚Äì2020)', '(2017‚Äì2018)', '(2018‚Äì2020)', '(2017‚Äì2019)', '(2011‚Äì2015)', '(2016‚Äì2018)', '(2012‚Äì2018)', '(2017)', '(2017‚Äì2019)', '(2018‚Äì2019)', '(2008‚Äì2015)', '(2016‚Äì2023)', '(2019)', '(2015‚Äì2019)', '(2013‚Äì2017)', '(2017‚Äì2019)', '(2005‚Äì )', '(2015‚Äì2019)', '(2018)']\n"
     ]
    }
   ],
   "source": [
    "print(Year_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cbd2b9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "genre = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for g in genre[0:100]:\n",
    "    Genre.append(g.text)\n",
    "print(len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f4194c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Drama, Horror, Mystery']\n"
     ]
    }
   ],
   "source": [
    "print(Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "938c290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "runt = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for r in runt[0:100]:\n",
    "    Run_time.append(r.text)\n",
    "print(len(Run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a585d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4,189 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '5,702 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '3,030 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '5,280 min', '4,576 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '3,804 min', '1,455 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '5,076 min', '44 min', '22 min', '43 min', '44 min', '2,109 min', '7,788 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '3,154 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '356 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min']\n"
     ]
    }
   ],
   "source": [
    "print(Run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e47eb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"lister-item\")))\n",
    "\n",
    "votes = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    try:\n",
    "        vote_xpath = f\"(//p[@class='text-muted text-small'])//span[@name='nv']\"\n",
    "        vote_element = driver.find_element(By.XPATH, vote_xpath)\n",
    "        votes.append(vote_element.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting vote for item {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "022c30c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932', '2,225,932']\n"
     ]
    }
   ],
   "source": [
    "print(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d161891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "ratings = driver.find_elements(By.XPATH,'//span[@class=\"ipl-rating-star__rating\"]')\n",
    "for r in ratings[0:100]:\n",
    "    Ratings.append(r.text)\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d3940029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.DataFrame({\n",
    "    'Name': Name,\n",
    "    'Year': Year_span,\n",
    "    'Genre': Genre,\n",
    "    'Runtime': Run_time,\n",
    "    'Ratings': Ratings,\n",
    "    'Votes':votes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1caf1c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Name         Year                     Genre  \\\n",
      "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
      "1                  Stranger Things  (2016‚Äì2025)    Drama, Fantasy, Horror   \n",
      "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
      "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
      "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
      "..                             ...          ...                       ...   \n",
      "95                           Reign  (2013‚Äì2017)                     Drama   \n",
      "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
      "97                  Criminal Minds     (2005‚Äì )     Crime, Drama, Mystery   \n",
      "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
      "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
      "\n",
      "      Runtime Ratings      Votes  \n",
      "0   4,189 min     9.2  2,225,932  \n",
      "1      51 min          2,225,932  \n",
      "2      44 min    Rate  2,225,932  \n",
      "3      60 min          2,225,932  \n",
      "4      43 min          2,225,932  \n",
      "..        ...     ...        ...  \n",
      "95     42 min          2,225,932  \n",
      "96     50 min          2,225,932  \n",
      "97     42 min          2,225,932  \n",
      "98     45 min          2,225,932  \n",
      "99    572 min          2,225,932  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695c249",
   "metadata": {},
   "source": [
    "Q8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7dd16c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ecd2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "designation.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9e11dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[] \n",
    "Number_of_instance=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "subject_area=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e2e0809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris', 'Heart Disease', 'Adult', 'Wine', 'Breast Cancer Wisconsin (Diagnostic)', 'Diabetes', 'Dry Bean Dataset', 'Car Evaluation', 'Wine Quality', 'Rice (Cammeo and Osmancik)']\n"
     ]
    }
   ],
   "source": [
    "name = driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]')\n",
    "for n in name[0:11]:\n",
    "    Name.append(n.text)\n",
    "print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14d2de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Task                  Data_Type Number_of_Instance  \\\n",
      "0              Classification                    Tabular      150 Instances   \n",
      "1              Classification               Multivariate      303 Instances   \n",
      "2              Classification               Multivariate   48.84K Instances   \n",
      "3              Classification                    Tabular      178 Instances   \n",
      "4              Classification               Multivariate      569 Instances   \n",
      "5              Classification  Multivariate, Time-Series        1 Instances   \n",
      "6              Classification               Multivariate   13.61K Instances   \n",
      "7              Classification               Multivariate    1.73K Instances   \n",
      "8  Classification, Regression               Multivariate     4.9K Instances   \n",
      "9              Classification               Multivariate    3.81K Instances   \n",
      "\n",
      "  No_of_Attribute  \n",
      "0      4 Features  \n",
      "1     13 Features  \n",
      "2     14 Features  \n",
      "3     13 Features  \n",
      "4     30 Features  \n",
      "5     20 Features  \n",
      "6     16 Features  \n",
      "7      6 Features  \n",
      "8     12 Features  \n",
      "9      7 Features  \n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "dataset = driver.find_elements(By.XPATH, \"//div[contains(@class, 'my-2 hidden gap-4 md:grid grid-cols-12')]\")\n",
    "\n",
    "#Limiting the loop\n",
    "counter = 0\n",
    "\n",
    "for d in dataset:\n",
    "    if counter < 10:\n",
    "        findc = d.find_elements(By.XPATH, \".//div[contains(@class, 'col-span-3 flex items-center gap-2')]\")\n",
    "        \n",
    "        if len(findc) >= 4:\n",
    "            task = findc[0].text\n",
    "            data_type = findc[1].text\n",
    "            number_of_instance = findc[2].text\n",
    "            no_of_attribute = findc[3].text\n",
    "\n",
    "            data_List = {\n",
    "                'Task': task,\n",
    "                'Data_Type': data_type,\n",
    "                'Number_of_Instance': number_of_instance,\n",
    "                'No_of_Attribute': no_of_attribute\n",
    "            }\n",
    "\n",
    "            data_list.append(data_List)\n",
    "        \n",
    "        counter += 1\n",
    "df = pd.DataFrame(data_list)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "37c1df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_area = []\n",
    "attribute = []\n",
    "year = []\n",
    "views = []\n",
    "try:\n",
    "    rows1 = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//tbody[@class=\"border\"]/tr'))\n",
    "    )\n",
    "    for row in rows1[:11]:\n",
    "        subject_area.append(row.find_element(By.XPATH, \"./td[1]\").text)\n",
    "        attribute.append(row.find_element(By.XPATH, \"./td[2]\").text)\n",
    "        year.append(row.find_element(By.XPATH, \"./td[3]\").text)\n",
    "        views.append(row.find_element(By.XPATH, \"./td[4]\").text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "461d4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biology', 'Health and Medicine', 'Social Science', 'Physics and Chemistry', 'Health and Medicine', 'Health and Medicine', 'Biology', 'Other', 'Business', 'Biology']\n"
     ]
    }
   ],
   "source": [
    "print(subject_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "416cfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.DataFrame({\n",
    "    'Subject': subject_area,\n",
    "    'Attribute': attribute,\n",
    "    'Year': year,\n",
    "    'Views': views,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a3f6870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Subject                   Attribute       Year    Views\n",
      "0                Biology                        Real   7/1/1988  503.33K\n",
      "1    Health and Medicine  Categorical, Integer, Real   7/1/1988  355.01K\n",
      "2         Social Science        Categorical, Integer   5/1/1996  277.93K\n",
      "3  Physics and Chemistry               Integer, Real   7/1/1991  221.82K\n",
      "4    Health and Medicine                        Real  11/1/1995  212.25K\n",
      "5    Health and Medicine        Categorical, Integer        N/A  185.39K\n",
      "6                Biology               Integer, Real  9/14/2020  171.22K\n",
      "7                  Other                 Categorical   6/1/1997  167.52K\n",
      "8               Business                        Real  10/7/2009  155.55K\n",
      "9                Biology                        Real  10/6/2019  127.07K\n"
     ]
    }
   ],
   "source": [
    "print(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814372f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
